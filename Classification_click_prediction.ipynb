{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Предсказание кликов пользователя"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Одним из важнейших сигналов для рекомендательной системы является поведение пользователя. Таких данных зачастую достаточно, чтобы построить бейзлайн приемлемого качества.\n",
    "\n",
    "В этом задании нужно построить рекомендательную систему на основе данных о действиях пользователей в персональной ленте рекомендаций Яндекс.Дзена.\n",
    "\n",
    "Доступны 2 датасета: тренировочный (train.csv) и тестовый (test.csv). Каждая строка в датасетах соответствует взаимодействию некоторого пользователя с некоторым документом, показанным ему в ленте рекомендаций. Датасеты содержат следующие колонки:\n",
    "\n",
    "sample_id — числовой id взаимодействия,  \n",
    "item — числовой id показанного пользователю документа,  \n",
    "publisher — числовой id автора документа,  \n",
    "user — числовой id пользователя,  \n",
    "topic_i, weight_i — числовой id i-ой темы документа и степень принадлежности документа данной теме (целое число от 0 до 100) (i = 0,1,2,3,4)  \n",
    "target — факт клика пользователя на документ (1 — был клик, 0 — был показ без клика). Этот столбец присутствует только в  \n",
    "    тренировочном датасете.\n",
    "    \n",
    "Необходимо построить модель для предсказания кликов пользователя и применить её к тестовому датасету.\n",
    "\n",
    "В качестве решения необходимо создать csv-файл, состоящий из двух колонок: sample_id и target, где sample_id — id строки из тестового датасета, а target — предсказанная вероятность клика. Количество строк в этом файле должно совпадать с количеством строк в test.csv. Строки в файле с решением должны быть отсортированы по возрастанию значений колонки sample_id (в том же порядке, что и в test.csv). Все значения вероятностей в колонке target должны быть вещественными числами от 0 до 1.\n",
    "\n",
    "Датасеты можно скачать по ссылке: https://yadi.sk/d/pVna8ejcnQZK_A."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standard imports\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#csv to pandas dataframe\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_id</th>\n",
       "      <th>item</th>\n",
       "      <th>publisher</th>\n",
       "      <th>user</th>\n",
       "      <th>topic_0</th>\n",
       "      <th>topic_1</th>\n",
       "      <th>topic_2</th>\n",
       "      <th>topic_3</th>\n",
       "      <th>topic_4</th>\n",
       "      <th>weight_0</th>\n",
       "      <th>weight_1</th>\n",
       "      <th>weight_2</th>\n",
       "      <th>weight_3</th>\n",
       "      <th>weight_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1009109</td>\n",
       "      <td>1716</td>\n",
       "      <td>349</td>\n",
       "      <td>1053</td>\n",
       "      <td>362</td>\n",
       "      <td>397</td>\n",
       "      <td>430</td>\n",
       "      <td>287</td>\n",
       "      <td>431</td>\n",
       "      <td>54</td>\n",
       "      <td>54</td>\n",
       "      <td>51</td>\n",
       "      <td>26</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1009110</td>\n",
       "      <td>1707</td>\n",
       "      <td>202</td>\n",
       "      <td>254</td>\n",
       "      <td>150</td>\n",
       "      <td>73</td>\n",
       "      <td>356</td>\n",
       "      <td>212</td>\n",
       "      <td>482</td>\n",
       "      <td>29</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1009111</td>\n",
       "      <td>1592</td>\n",
       "      <td>520</td>\n",
       "      <td>1524</td>\n",
       "      <td>397</td>\n",
       "      <td>287</td>\n",
       "      <td>356</td>\n",
       "      <td>330</td>\n",
       "      <td>281</td>\n",
       "      <td>95</td>\n",
       "      <td>46</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1009112</td>\n",
       "      <td>1541</td>\n",
       "      <td>82</td>\n",
       "      <td>2994</td>\n",
       "      <td>397</td>\n",
       "      <td>287</td>\n",
       "      <td>102</td>\n",
       "      <td>323</td>\n",
       "      <td>356</td>\n",
       "      <td>93</td>\n",
       "      <td>77</td>\n",
       "      <td>25</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1009113</td>\n",
       "      <td>52</td>\n",
       "      <td>520</td>\n",
       "      <td>936</td>\n",
       "      <td>201</td>\n",
       "      <td>283</td>\n",
       "      <td>618</td>\n",
       "      <td>249</td>\n",
       "      <td>617</td>\n",
       "      <td>35</td>\n",
       "      <td>33</td>\n",
       "      <td>30</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sample_id  item  publisher  user  topic_0  topic_1  topic_2  topic_3  \\\n",
       "0    1009109  1716        349  1053      362      397      430      287   \n",
       "1    1009110  1707        202   254      150       73      356      212   \n",
       "2    1009111  1592        520  1524      397      287      356      330   \n",
       "3    1009112  1541         82  2994      397      287      102      323   \n",
       "4    1009113    52        520   936      201      283      618      249   \n",
       "\n",
       "   topic_4  weight_0  weight_1  weight_2  weight_3  weight_4  \n",
       "0      431        54        54        51        26        13  \n",
       "1      482        29         7         5         5         4  \n",
       "2      281        95        46         6         5         3  \n",
       "3      356        93        77        25         7         4  \n",
       "4      617        35        33        30        11         9  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_id</th>\n",
       "      <th>item</th>\n",
       "      <th>publisher</th>\n",
       "      <th>user</th>\n",
       "      <th>topic_0</th>\n",
       "      <th>topic_1</th>\n",
       "      <th>topic_2</th>\n",
       "      <th>topic_3</th>\n",
       "      <th>topic_4</th>\n",
       "      <th>weight_0</th>\n",
       "      <th>weight_1</th>\n",
       "      <th>weight_2</th>\n",
       "      <th>weight_3</th>\n",
       "      <th>weight_4</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>531</td>\n",
       "      <td>147</td>\n",
       "      <td>2925</td>\n",
       "      <td>411</td>\n",
       "      <td>477</td>\n",
       "      <td>618</td>\n",
       "      <td>249</td>\n",
       "      <td>460</td>\n",
       "      <td>27</td>\n",
       "      <td>18</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1574</td>\n",
       "      <td>260</td>\n",
       "      <td>2981</td>\n",
       "      <td>212</td>\n",
       "      <td>287</td>\n",
       "      <td>382</td>\n",
       "      <td>302</td>\n",
       "      <td>51</td>\n",
       "      <td>27</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>940</td>\n",
       "      <td>394</td>\n",
       "      <td>1230</td>\n",
       "      <td>145</td>\n",
       "      <td>150</td>\n",
       "      <td>212</td>\n",
       "      <td>170</td>\n",
       "      <td>174</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>52</td>\n",
       "      <td>520</td>\n",
       "      <td>2597</td>\n",
       "      <td>201</td>\n",
       "      <td>283</td>\n",
       "      <td>618</td>\n",
       "      <td>249</td>\n",
       "      <td>617</td>\n",
       "      <td>35</td>\n",
       "      <td>33</td>\n",
       "      <td>30</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>766</td>\n",
       "      <td>55</td>\n",
       "      <td>1680</td>\n",
       "      <td>362</td>\n",
       "      <td>150</td>\n",
       "      <td>477</td>\n",
       "      <td>305</td>\n",
       "      <td>388</td>\n",
       "      <td>51</td>\n",
       "      <td>15</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sample_id  item  publisher  user  topic_0  topic_1  topic_2  topic_3  \\\n",
       "0          0   531        147  2925      411      477      618      249   \n",
       "1          1  1574        260  2981      212      287      382      302   \n",
       "2          2   940        394  1230      145      150      212      170   \n",
       "3          3    52        520  2597      201      283      618      249   \n",
       "4          4   766         55  1680      362      150      477      305   \n",
       "\n",
       "   topic_4  weight_0  weight_1  weight_2  weight_3  weight_4  target  \n",
       "0      460        27        18         9         8         7       0  \n",
       "1       51        27        11         2         1         0       0  \n",
       "2      174         7         6         6         5         5       0  \n",
       "3      617        35        33        30        11         9       1  \n",
       "4      388        51        15        13        10         9       1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    805481\n",
       "1    203628\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Is dataset balanced?\n",
    "train['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataset balancing\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_majority = train[train.target==0]\n",
    "train_minority = train[train.target==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    805481\n",
       "0    805481\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Upsample minority class\n",
    "train_minority_upsampled = resample(train_minority, \n",
    "                                 replace=True,     # sample with replacement\n",
    "                                 n_samples=805481,    # to match majority class\n",
    "                                 random_state=42) # reproducible results\n",
    "\n",
    " \n",
    "# Combine majority class with upsampled minority class\n",
    "train_balanced = pd.concat([train_majority, train_minority_upsampled])\n",
    " \n",
    "# Display new class counts\n",
    "train_balanced.target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_balanced = train_balanced.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataset for training (balanced)\n",
    "train_ds = train_balanced.drop(['target', 'sample_id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Targets for training (balanced)\n",
    "train_targets = train_balanced['target'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test dataset\n",
    "test_ds = test.drop(['sample_id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standard import for features manipulation\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Numerical and categorical attributes (features)\n",
    "num_attribs = ['weight_0', 'weight_1', 'weight_2', 'weight_3', 'weight_4']\n",
    "cat_attribs = ['item', 'publisher', 'user', 'topic_0', 'topic_1', 'topic_2', 'topic_3', 'topic_4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying OneHotEncoder for categorical attributes and StandardScaler for numerical attributes\n",
    "data_prep = ColumnTransformer([\n",
    "        (\"cat\", OneHotEncoder(categories = 'auto'), cat_attribs),\n",
    "        (\"num\", StandardScaler(), num_attribs),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds_prepared = data_prep.fit_transform(train_ds.astype(np.float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds_prepared = data_prep.transform(test_ds.astype(np.float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds_prepared = train_ds_prepared.astype('float32')\n",
    "train_targets = train_targets.astype('float32')\n",
    "test_ds_prepared = test_ds_prepared.astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "log_reg = LogisticRegression(solver = 'sag')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.67212861, 0.67261838, 0.67116275])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Cross val ccuracy score\n",
    "cross_val_score(log_reg, train_ds_prepared, train_targets, cv=3, scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy score is about 0.67"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying Densed NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#Standard NN (Keras) import\n",
    "from keras import models\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "#Model construction\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(16, activation='relu', input_shape=(7573,)))\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training & validating set split\n",
    "x_val = train_ds_prepared[:500000]\n",
    "partial_x_train = train_ds_prepared[500000:]\n",
    "y_val = train_targets[:500000]\n",
    "partial_y_train = train_targets[500000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model compilation\n",
    "model.compile(optimizer='rmsprop',\n",
    "loss='binary_crossentropy',\n",
    "metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 1110962 samples, validate on 500000 samples\n",
      "Epoch 1/20\n",
      "1110962/1110962 [==============================] - 41s 37us/step - loss: 0.6193 - acc: 0.6535 - val_loss: 0.6061 - val_acc: 0.6675\n",
      "Epoch 2/20\n",
      "1110962/1110962 [==============================] - 41s 37us/step - loss: 0.6001 - acc: 0.6729 - val_loss: 0.6009 - val_acc: 0.6717\n",
      "Epoch 3/20\n",
      "1110962/1110962 [==============================] - 41s 37us/step - loss: 0.5961 - acc: 0.6761 - val_loss: 0.6003 - val_acc: 0.6727\n",
      "Epoch 4/20\n",
      "1110962/1110962 [==============================] - 40s 36us/step - loss: 0.5932 - acc: 0.6792 - val_loss: 0.5974 - val_acc: 0.6757\n",
      "Epoch 5/20\n",
      "1110962/1110962 [==============================] - 39s 35us/step - loss: 0.5907 - acc: 0.6821 - val_loss: 0.5968 - val_acc: 0.6770\n",
      "Epoch 6/20\n",
      "1110962/1110962 [==============================] - 39s 35us/step - loss: 0.5883 - acc: 0.6851 - val_loss: 0.5958 - val_acc: 0.6779\n",
      "Epoch 7/20\n",
      "1110962/1110962 [==============================] - 39s 35us/step - loss: 0.5864 - acc: 0.6875 - val_loss: 0.5954 - val_acc: 0.6794\n",
      "Epoch 8/20\n",
      "1110962/1110962 [==============================] - 39s 35us/step - loss: 0.5846 - acc: 0.6899 - val_loss: 0.5944 - val_acc: 0.6808\n",
      "Epoch 9/20\n",
      "1110962/1110962 [==============================] - 39s 35us/step - loss: 0.5827 - acc: 0.6920 - val_loss: 0.5956 - val_acc: 0.6808\n",
      "Epoch 10/20\n",
      "1110962/1110962 [==============================] - 39s 35us/step - loss: 0.5809 - acc: 0.6944 - val_loss: 0.5936 - val_acc: 0.6822\n",
      "Epoch 11/20\n",
      "1110962/1110962 [==============================] - 39s 35us/step - loss: 0.5790 - acc: 0.6964 - val_loss: 0.5929 - val_acc: 0.6829\n",
      "Epoch 12/20\n",
      "1110962/1110962 [==============================] - 39s 35us/step - loss: 0.5774 - acc: 0.6985 - val_loss: 0.5919 - val_acc: 0.6843\n",
      "Epoch 13/20\n",
      "1110962/1110962 [==============================] - 39s 35us/step - loss: 0.5758 - acc: 0.7002 - val_loss: 0.5916 - val_acc: 0.6857\n",
      "Epoch 14/20\n",
      "1110962/1110962 [==============================] - 40s 36us/step - loss: 0.5743 - acc: 0.7017 - val_loss: 0.5919 - val_acc: 0.6864\n",
      "Epoch 15/20\n",
      "1110962/1110962 [==============================] - 40s 36us/step - loss: 0.5730 - acc: 0.7035 - val_loss: 0.5907 - val_acc: 0.6868\n",
      "Epoch 16/20\n",
      "1110962/1110962 [==============================] - 40s 36us/step - loss: 0.5718 - acc: 0.7044 - val_loss: 0.5915 - val_acc: 0.6873\n",
      "Epoch 17/20\n",
      "1110962/1110962 [==============================] - 41s 36us/step - loss: 0.5708 - acc: 0.7056 - val_loss: 0.5912 - val_acc: 0.6882\n",
      "Epoch 18/20\n",
      "1110962/1110962 [==============================] - 40s 36us/step - loss: 0.5697 - acc: 0.7067 - val_loss: 0.5900 - val_acc: 0.68864s \n",
      "Epoch 19/20\n",
      "1110962/1110962 [==============================] - 39s 35us/step - loss: 0.5688 - acc: 0.7075 - val_loss: 0.5895 - val_acc: 0.6886\n",
      "Epoch 20/20\n",
      "1110962/1110962 [==============================] - 39s 35us/step - loss: 0.5678 - acc: 0.7083 - val_loss: 0.5898 - val_acc: 0.6882\n"
     ]
    }
   ],
   "source": [
    "#Model fitting\n",
    "history = model.fit(partial_x_train,\n",
    "partial_y_train,\n",
    "epochs=20,\n",
    "batch_size=512,\n",
    "validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy score on early stopping (epoch 19) is about 0.689"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying RandomForestClassifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_forest = RandomForestClassifier(n_estimators = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fine tuning with GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'max_features': [40, 60],\n",
    "    'n_estimators': [5, 10]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(rand_forest, param_grid, cv=3, scoring=\"accuracy\", verbose=2, n_jobs=-1, return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed: 81.5min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed: 81.5min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'max_features': [40, 60], 'n_estimators': [5, 10]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='accuracy', verbose=2)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(train_ds_prepared, train_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_features': 40, 'n_estimators': 10}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#best parameters\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features=40, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8839221533468822 {'max_features': 40, 'n_estimators': 5}\n",
      "0.9174778796768639 {'max_features': 40, 'n_estimators': 10}\n",
      "0.8864945293557515 {'max_features': 60, 'n_estimators': 5}\n",
      "0.9110848052281805 {'max_features': 60, 'n_estimators': 10}\n"
     ]
    }
   ],
   "source": [
    "cvres = grid_search.cv_results_\n",
    "for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
    "    print(mean_score, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best accuracy score is 0.917 for 'max_features': 40, 'n_estimators': 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fine tuning with 'n_estimators': [20, 30]\n",
    "param_grid = {\n",
    "    'max_features': [40],\n",
    "    'n_estimators': [20, 30]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(rand_forest, param_grid, cv=3, scoring=\"accuracy\", verbose=2, n_jobs=-1, return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   6 | elapsed: 71.5min remaining: 71.5min\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed: 148.5min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'max_features': [40], 'n_estimators': [20, 30]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='accuracy', verbose=2)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(train_ds_prepared, train_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9226158034764321 {'max_features': 40, 'n_estimators': 20}\n",
      "0.9239994487765695 {'max_features': 40, 'n_estimators': 30}\n"
     ]
    }
   ],
   "source": [
    "cvres = grid_search.cv_results_\n",
    "for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
    "    print(mean_score, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_features': 40, 'n_estimators': 30}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best accuracy score is 0.924 for 'max_features': 40, 'n_estimators': 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features=40, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Best estimator\n",
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_grid = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Target probabilities prediction using best estimator\n",
    "prediction_randforest = best_grid.predict_proba(test_ds_prepared)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.3       , 0.33333333, 0.06666667, ..., 0.13333333, 0.23333333,\n",
       "       0.33333333])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_randforest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pandas data frame preparation for results\n",
    "prediction_rforest = test[[\"sample_id\"]].copy()\n",
    "prediction_rforest[\"target\"] = np.around(prediction_randforest, decimals=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting to csv\n",
    "prediction_rforest.to_csv(\"prediction_rforest.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best accuracy score is 0.924 for RandomForestClassifier with parameters: 'max_features': 40, 'n_estimators': 30"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
